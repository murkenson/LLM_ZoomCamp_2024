# Module 4: Monitoring

In this module, we will learn how to monitor our LLM and RAG system. We will collect, store and visualize metrics to assess the answer quality of LLMs as well as chat history and user feedback. 

## Prerequisites

Add OPENAI_API_KEY as environment variable
```
Mac/Linux: export OPENAI_API_KEY="your-api-key-here"
```
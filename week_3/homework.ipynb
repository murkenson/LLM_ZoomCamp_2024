{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c16e42ce-cae7-4a5b-9772-2a06e3d0318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.42.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers) (2.3.0+cpu)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e3d33-0c94-47a7-a393-90202f56aba5",
   "metadata": {},
   "source": [
    ">Run Elastic Search 8.4.3 using Docker:\n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "    -m 4GB \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d166676b-961a-42d9-91ef-2ba88aaa935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm\n",
    "import requests \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93052ba-8e04-4038-8c41-a018ac954e79",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings model `multi-qa-distilbert-cos-v1` from\n",
    "[the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "```bash\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embedding for this user question:\n",
    "\n",
    "```python\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "```\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "\n",
    "* -0.24\n",
    "* -0.04\n",
    "* **0.07**\n",
    "* 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "674a1442-d45e-4a3e-98b5-aa16998f164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"multi-qa-distilbert-cos-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d782bb4-e049-4904-93c3-e8c91a3a1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5136e7-b8c4-4257-a132-cfb13051381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbb68fd8-45cc-4eb7-9f6b-6acf9819e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd809089-0a76-4007-8c3b-2309e5aef51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first value of the first column is: 0.07822265475988388\n"
     ]
    }
   ],
   "source": [
    "first_value = vec[0]\n",
    "print(f\"The first value of the first column is: {first_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13edaa-0a4b-40c5-bac0-94d8a3aced54",
   "metadata": {},
   "source": [
    "## Prepare the documents\n",
    "\n",
    "Now we will create the embeddings for the documents.\n",
    "\n",
    "Load the documents with ids that we prepared in the module:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "```\n",
    "\n",
    "We will use only a subset of the questions - the questions\n",
    "for `\"machine-learning-zoomcamp\"`. After filtering, you should\n",
    "have only 375 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91ba845a-eb87-4cdd-83b8-ea44a237f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c11b5fef-4949-4276-8b3b-ca8cab97a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document: {'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork', 'section': 'General course-related questions', 'question': 'How do I sign up?', 'course': 'machine-learning-zoomcamp', 'id': '0227b872'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample document:\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b4fd21a-f1b3-4c4e-8ea3-ff6788b3827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(filter(lambda doc: doc[\"course\"] == \"machine-learning-zoomcamp\", documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7411ec7-36fb-40d9-98a0-e1ed1a1fc1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5c5d9-7efa-491e-837e-3af1755e11ba",
   "metadata": {},
   "source": [
    "## Q2. Creating the embeddings\n",
    "\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix `X`:\n",
    "\n",
    "- Create a list `embeddings` \n",
    "- Iterate over each document \n",
    "- `qa_text = f'{question} {text}'`\n",
    "- compute the embedding for `qa_text`, append to `embeddings`\n",
    "- At the end, let `X = np.array(embeddings)` (`import numpy as np`) \n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51db867a-eec7-4a77-b9cd-8694b713a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for doc in documents:\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qa_text = f'{question} {text}'\n",
    "    embeddings.append(embedding_model.encode(qa_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e36ccb4b-7be6-4ed0-b754-0f5350fadf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The len embeddings: 375\n",
      "The len first embeddings: 768\n"
     ]
    }
   ],
   "source": [
    "print(f\"The len embeddings: {len(embeddings)}\")\n",
    "print(f\"The len first embeddings: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f351631-32e0-4c29-8a06-461629a526a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is (375, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(embeddings)\n",
    "print(f\"The shape is {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b286a-b260-49cf-8375-69af411156f5",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "\n",
    "We have the embeddings and the query vector. Now let's compute the \n",
    "cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2. \n",
    "\n",
    "The vectors returned from the embedding model are already\n",
    "normalized (you can check it by computing a dot product of a vector\n",
    "with itself - it should return something very close to 1.0). This means that in order\n",
    "to compute the coside similarity, it's sufficient to \n",
    "multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "- 65.0 \n",
    "- 6.5\n",
    "- **0.65**\n",
    "- 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "996298f8-d8cc-4035-8da4-42a305f57243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.dot(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87b5de07-d016-4355-b7e4-58932932ca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score in the results is 0.6506572961807251\n"
     ]
    }
   ],
   "source": [
    "scores = X.dot(vec)\n",
    "np.max(scores)\n",
    "print(f\"The highest score in the results is {np.max(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92b451fa-f58b-4211-b570-2d8f77138db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'ee58a693'},\n",
       " {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I just joined. What should I do next? How can I access course materials?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '0a278fb2'},\n",
       " {'text': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I filled the form, but haven't received a confirmation email. Is it normal?\",\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '6ba259b1'},\n",
       " {'text': 'Technically, yes. Advisable? Not really. Reasons:\\nSome homework(s) asks for specific python library versions.\\nAnswers may not match in MCQ options if using different languages other than Python 3.10 (the recommended version for 2023 cohort)\\nAnd as for midterms/capstones, your peer-reviewers may not know these other languages. Do you want to be penalized for others not knowing these other languages?\\nYou can create a separate repo using course’s lessons but written in other languages for your own learnings, but not advisable for submissions.\\ntx[source]',\n",
       "  'section': 'Miscellaneous',\n",
       "  'question': 'Can I do the course in other languages, like R or Scala?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '9f261648'},\n",
       " {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'e7ba6b8a'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, vecuery, num_results=10):\n",
    "        scores = self.embeddings.dot(vecuery)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(vec, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad95693f-a5d7-4678-8a6c-33c1dc3a7afa",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "We can now compute the similarity between a query vector and all the embeddings.\n",
    "\n",
    "Let's use this to implement our own vector search\n",
    "\n",
    "```python\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)\n",
    "```\n",
    "\n",
    "If you don't understand how the `search` function work:\n",
    "\n",
    "* Ask ChatGTP or any other LLM of your choice to explain the code\n",
    "* Check our pre-course workshop about implementing a search engine [here](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "\n",
    "(Note: you can replace `argsort` with `argpartition` to make it a lot faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd0a38-fb11-4c36-8fc4-f053f7254ff1",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will\n",
    "use the hitrate metric for evaluation.\n",
    "\n",
    "First, load the ground truth dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Now use the code from the module to calculate the hitrate of\n",
    "`VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "What did you get?\n",
    "\n",
    "* **0.93**\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "617d4fc7-7ed8-44c0-9dfb-8a223baa6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc56f956-421c-4ea7-8583-8da278e16ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6648fbd7-b2fc-4178-8c10-b9fb383940c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(q):\n",
    "    vec = embedding_model.encode(q)\n",
    "    return search_engine.search(vec, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a34a653-0370-49bf-a683-8a8a773a0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "258a9640-2061-437f-b1db-3614aa04c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8942d33-96ee-4b7d-a5de-e2d7fa715f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        question = q['question']\n",
    "        results = search_function(question)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2fcab99-1a67-4b86-86a5-ac604e90753e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d3cbf9dfd04763bb1820b30ef21245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9398907103825137, 'mrr': 0.8516484517304189}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, vector_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0385c-e456-46b9-921c-5fc70df21add",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch\n",
    "\n",
    "Now let's index these documents with elasticsearch\n",
    "\n",
    "* Create the index with the same settings as in the module (but change the dimensions)\n",
    "* Index the embeddings (note: you've already computed them)\n",
    "\n",
    "After indexing, let's perform the search of the same query from Q1.\n",
    "\n",
    "What's the ID of the document with the highest score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "299deaa5-dbd0-47ba-ae11-b5ec6a1016e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'How do I sign up?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'id': '0227b872'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cee3fd31-748d-4f8b-a22f-6bd60bf69077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4eb0fb25-d9b6-44c0-a41b-4fdd16dcf85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3961206b784801a9a7ac9da2959a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc, embedding in tqdm(zip(documents, embeddings)):\n",
    "    doc['question_text_vector'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d1a54df-6d38-4aff-92c6-4e92304e1135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'How do I sign up?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'id': '0227b872',\n",
       " 'question_text_vector': array([ 8.80590528e-02,  1.55935483e-02,  7.92558193e-02,  2.52757873e-02,\n",
       "         7.55765066e-02, -3.90596949e-02, -4.13813852e-02,  2.52918135e-02,\n",
       "         2.43241284e-02,  3.62585997e-03, -7.28285545e-03, -3.28751542e-02,\n",
       "         6.12956472e-02, -5.71101010e-02,  1.16774784e-02, -1.79442130e-02,\n",
       "         4.49206047e-02, -5.41605875e-02, -1.92261033e-03,  1.48329930e-02,\n",
       "         7.91360065e-03, -3.43127362e-02,  1.21480487e-02,  1.27185713e-02,\n",
       "        -1.60092711e-02,  7.12137856e-03,  1.58389509e-02, -3.27488902e-04,\n",
       "         3.01296543e-03, -4.58918400e-02, -1.34775438e-03,  2.01149546e-02,\n",
       "         2.33724471e-02, -4.28200746e-03, -3.09384037e-02,  1.94302748e-03,\n",
       "        -1.88219752e-02,  5.35160303e-03,  1.29352352e-02, -3.23957913e-02,\n",
       "         3.10556218e-02,  5.12981648e-03, -3.24394932e-04, -3.15541998e-02,\n",
       "         1.93377174e-02, -6.38601556e-02, -3.05381045e-02, -6.27884790e-02,\n",
       "        -1.74859781e-02,  3.52949575e-02, -2.98071913e-02,  7.45346099e-02,\n",
       "        -2.06183232e-02, -1.79156959e-02,  1.86262634e-02,  5.31014837e-02,\n",
       "         1.19287465e-02, -5.18544056e-02, -1.61922548e-03,  3.58705893e-02,\n",
       "        -6.52320497e-03,  4.53287326e-02, -1.06173949e-02,  1.02415644e-02,\n",
       "        -4.41201888e-02, -7.07985684e-02,  1.33665288e-02, -2.05062665e-02,\n",
       "         3.62042226e-02, -3.39450836e-02,  3.25139165e-02,  2.22205129e-02,\n",
       "        -3.24136913e-02, -3.93159091e-02,  2.75360711e-04,  2.43686568e-02,\n",
       "         1.57890059e-02,  2.50409115e-02,  1.70958682e-03, -2.63328431e-04,\n",
       "         4.40217033e-02, -5.46364971e-02,  2.34349463e-02,  2.99487058e-02,\n",
       "         1.41274724e-02, -2.91330498e-02, -6.47386396e-03, -3.54053676e-02,\n",
       "         1.71305165e-02,  2.90904641e-02,  1.46859018e-02,  8.54341406e-03,\n",
       "        -3.44416797e-02, -1.04836151e-02,  3.15485746e-02, -8.74644071e-02,\n",
       "        -2.11829543e-02, -5.05227298e-02, -7.52344867e-03,  4.42793556e-02,\n",
       "         3.77510227e-02, -1.24977960e-03,  6.45406265e-03, -1.53079126e-02,\n",
       "         1.66407283e-02,  5.46391420e-02,  1.78500600e-02, -7.61282956e-03,\n",
       "        -4.61103097e-02,  4.10019495e-02, -4.52273414e-02, -2.77623236e-02,\n",
       "         1.95288528e-02, -6.11867569e-02,  1.12644220e-02,  5.08541614e-03,\n",
       "         4.85851355e-02, -9.06991120e-03, -9.79336444e-03,  1.72461290e-02,\n",
       "        -7.30905160e-02,  5.36574014e-02, -3.24015319e-02,  1.24104507e-02,\n",
       "         1.06903296e-02,  3.30721624e-02,  4.14839610e-02,  3.38428654e-02,\n",
       "        -1.12890464e-03, -9.08526033e-02,  3.76021978e-03, -3.49575207e-02,\n",
       "         1.31473681e-02,  1.33827794e-02,  3.44474465e-02,  6.85054511e-02,\n",
       "        -1.42454617e-02, -5.42298891e-02, -8.57380219e-03,  2.42687780e-02,\n",
       "         5.15870042e-02, -2.89775599e-02, -1.47677660e-02, -1.08239362e-02,\n",
       "        -5.66393621e-02, -2.07525073e-03, -3.71209942e-02,  4.00512712e-03,\n",
       "        -5.97901158e-02, -1.55888768e-02,  2.72703748e-02,  1.94720626e-02,\n",
       "         1.87415648e-02, -3.74510251e-02,  2.62067262e-02,  7.50287026e-02,\n",
       "         2.16101240e-02, -1.37813129e-02,  5.01988083e-02, -6.47027371e-03,\n",
       "         5.67430034e-02, -4.03868221e-02, -1.20674968e-02,  8.55052471e-02,\n",
       "        -2.71649961e-03,  2.78823506e-02, -4.38817367e-02, -2.82745175e-02,\n",
       "         1.92068573e-02, -4.36236970e-02,  3.98129337e-02, -5.63067161e-02,\n",
       "         1.37331067e-02,  4.01088549e-03, -7.01445201e-03, -1.51919499e-02,\n",
       "         4.40158024e-02,  2.72325277e-02,  3.32806744e-02,  3.21899466e-02,\n",
       "        -8.18990618e-02, -5.92770800e-02,  2.22220477e-02, -2.69076824e-02,\n",
       "         4.15942147e-02, -1.37761412e-02,  4.10629958e-02,  4.05325294e-02,\n",
       "        -5.58696501e-02,  3.60302478e-02, -6.35681208e-03, -1.65047310e-02,\n",
       "        -1.07167859e-03, -7.76118599e-03,  5.12158871e-02, -3.07670701e-02,\n",
       "        -3.98046896e-02,  2.19666455e-02, -9.50629823e-03,  2.66281273e-02,\n",
       "         3.57357077e-02,  5.89501299e-02,  5.54055814e-03, -1.41580345e-03,\n",
       "        -2.31177304e-02,  2.41293362e-03, -2.71170810e-02, -3.01101282e-02,\n",
       "        -1.71695370e-02, -3.58681865e-02, -4.03450690e-02,  2.02254299e-02,\n",
       "         1.31837679e-02, -1.05260238e-02,  1.65335145e-02, -1.22696450e-02,\n",
       "        -3.93680483e-02,  9.12598614e-03, -1.34845776e-02,  2.73655448e-02,\n",
       "         3.88677791e-02, -3.65220942e-03, -2.11339258e-02,  2.25957017e-04,\n",
       "        -3.12622264e-02, -3.47088836e-02, -4.12916020e-02,  2.91098561e-02,\n",
       "         5.44958934e-02, -1.32070005e-01,  9.59288701e-03, -1.37135331e-02,\n",
       "         4.40675467e-02, -1.03825808e-01,  6.36643097e-02,  8.60992260e-03,\n",
       "         1.49037736e-02,  8.22820468e-04, -2.20600106e-02, -9.55954369e-04,\n",
       "        -4.45745070e-04, -1.26143321e-02, -4.75995652e-02, -2.14227550e-02,\n",
       "         4.69317958e-02,  2.59529073e-02, -1.09704807e-02, -1.69420633e-02,\n",
       "         7.51990685e-03, -5.15509695e-02,  4.28996533e-02,  1.28123187e-03,\n",
       "        -1.04662776e-02, -1.64835844e-02, -4.98015136e-02,  4.39344123e-02,\n",
       "         5.84347360e-02, -4.44175526e-02,  6.89989887e-03,  5.39160557e-02,\n",
       "         1.75765753e-02,  7.08567863e-03, -2.18797270e-02, -1.89143023e-03,\n",
       "         1.05513325e-02, -5.98141588e-02, -3.13123837e-02, -2.73168515e-02,\n",
       "         3.12896781e-02,  5.49116768e-02, -1.85728744e-02, -2.15360932e-02,\n",
       "         6.17362894e-02,  7.07532093e-03,  2.01494396e-02, -4.06040736e-02,\n",
       "         2.30053049e-02,  2.01894883e-02,  1.80803407e-02,  3.35160829e-02,\n",
       "        -2.27059089e-02, -5.81537224e-02,  3.04264668e-02, -1.40142040e-02,\n",
       "         2.95398235e-02,  1.17535172e-02, -7.83733800e-02,  2.78972406e-02,\n",
       "        -4.30106334e-02, -7.59009346e-02,  4.92750779e-02,  7.59606138e-02,\n",
       "         3.54490872e-03,  5.81535846e-02,  4.69778441e-02, -4.00011148e-03,\n",
       "        -4.00546612e-03,  2.51615122e-02, -9.95811969e-02,  3.34291123e-02,\n",
       "        -3.01808584e-03,  3.01541518e-02,  4.54931632e-02, -7.25229904e-02,\n",
       "         4.01625857e-02, -1.16757173e-02, -6.19703997e-03, -9.54162404e-02,\n",
       "        -3.01121734e-02, -2.74963994e-02, -4.44820076e-02,  1.52521394e-03,\n",
       "        -6.31317645e-02, -8.02881345e-02,  4.55777943e-02,  3.08043733e-02,\n",
       "        -4.65144776e-03, -2.48239934e-03, -1.87035576e-02,  3.56814340e-02,\n",
       "        -8.61485824e-02, -8.76673125e-03,  5.94232902e-02,  7.03033656e-02,\n",
       "        -3.35510913e-03,  3.14285159e-02,  3.35557424e-02,  4.47359644e-02,\n",
       "        -1.82780158e-02,  4.33739601e-03, -1.56071940e-02,  4.82698269e-02,\n",
       "         5.78109361e-02, -1.55586109e-03, -3.07916403e-02,  3.06997541e-02,\n",
       "         3.05095799e-02,  4.37345244e-02, -2.46431548e-02, -1.98744517e-02,\n",
       "         7.25641195e-03,  3.61755751e-02, -1.86710358e-02, -1.69779789e-02,\n",
       "         5.28293438e-02,  1.72062847e-03,  3.34720723e-02, -6.57697096e-02,\n",
       "        -3.20816785e-02,  4.12177108e-03,  8.29502661e-03, -4.56412174e-02,\n",
       "         3.20225768e-02, -2.28897668e-02,  5.52556477e-02,  4.02578451e-02,\n",
       "        -2.90956870e-02, -3.44284368e-03, -1.38216969e-02, -6.29018701e-04,\n",
       "         2.53443997e-02,  1.89794172e-02, -4.45094444e-02, -4.78352718e-02,\n",
       "         3.22866440e-02,  6.68825358e-02, -8.67476407e-03, -7.80023867e-03,\n",
       "         2.92888121e-03, -2.42292266e-02, -2.09650975e-02, -1.09208792e-01,\n",
       "        -2.94364542e-02,  1.47712268e-02, -4.47422117e-02, -2.71011032e-02,\n",
       "        -3.91134899e-03,  1.68099739e-02,  3.11841425e-02,  1.24178706e-02,\n",
       "         6.59736386e-03, -4.44687949e-03, -3.45145576e-02, -1.24449958e-03,\n",
       "         5.61033227e-02, -4.12151478e-02,  4.74843197e-02,  3.92921194e-02,\n",
       "        -5.78539111e-02, -4.47588228e-02,  1.95152722e-02,  3.01113036e-02,\n",
       "        -8.72347225e-03, -2.85054818e-02, -7.27255270e-03,  3.58912759e-02,\n",
       "        -7.09610060e-02, -6.56752810e-02,  5.03814453e-03,  2.90020220e-02,\n",
       "         4.08615125e-03,  7.97066744e-03, -2.29644384e-02, -4.41172123e-02,\n",
       "         4.12212275e-02,  2.17066109e-02,  1.23129934e-02, -1.74234305e-02,\n",
       "        -1.55699085e-02, -1.17437784e-02,  5.18719628e-02,  3.44448234e-03,\n",
       "        -6.66774958e-02,  3.35144438e-02, -4.39756690e-03, -3.66432369e-02,\n",
       "         7.48344585e-02,  1.37544079e-02, -5.05722612e-02, -1.69507712e-02,\n",
       "        -9.13899243e-02,  3.94619927e-02, -4.91533838e-02,  2.32399292e-02,\n",
       "        -6.95739500e-03, -2.49377396e-02,  1.79814026e-02, -3.91750745e-02,\n",
       "         2.72794235e-02,  5.39087057e-02,  6.70257062e-02,  2.87340358e-02,\n",
       "         7.15201721e-03,  4.48691435e-02, -2.89590228e-02,  2.67861560e-02,\n",
       "         6.71392903e-02, -3.71879153e-03, -2.13471353e-02,  4.02928814e-02,\n",
       "         5.37431575e-02,  2.69312505e-03,  3.33235748e-02,  4.19459864e-02,\n",
       "         3.77101600e-02,  1.00906594e-02,  1.64033808e-02,  1.37284100e-02,\n",
       "         4.92302403e-02,  5.35364226e-02,  5.79526201e-02, -3.29139158e-02,\n",
       "         1.22460658e-02,  2.88261436e-02, -4.93663223e-03,  2.96172518e-02,\n",
       "         6.32615061e-03, -4.79912311e-02, -3.14917229e-02, -3.97242345e-02,\n",
       "        -3.50666344e-02,  2.99804704e-03, -9.44073498e-03,  2.62554619e-03,\n",
       "         9.90500487e-03, -5.18644899e-02,  2.04040613e-02,  3.75541709e-02,\n",
       "         8.65955278e-03,  3.73828635e-02,  2.54471917e-02, -1.32635077e-02,\n",
       "         8.06262940e-02,  2.10315734e-02, -1.99040771e-02, -1.00638522e-02,\n",
       "        -3.93789001e-02, -3.32227536e-02,  1.41281597e-02,  4.00279835e-02,\n",
       "        -7.60373333e-03, -4.89356741e-02, -2.67797466e-02, -5.59408367e-02,\n",
       "         3.21788639e-02,  8.22695252e-03,  3.76134627e-02,  8.17617960e-03,\n",
       "        -1.37846982e-02, -2.16961056e-02,  1.27261616e-02, -6.38870476e-03,\n",
       "        -8.46950524e-03, -6.06378634e-03, -1.16485571e-02,  1.15113994e-02,\n",
       "         2.72039752e-02, -1.29375355e-02, -1.30015276e-02,  3.71455401e-02,\n",
       "         2.18766071e-02,  2.41833478e-02,  3.43345251e-04, -1.44565478e-02,\n",
       "         3.24437879e-02,  5.78669794e-02,  1.25016235e-02,  1.83984302e-02,\n",
       "        -7.32085481e-02, -1.24307489e-02, -1.85830221e-02, -2.32730201e-03,\n",
       "         1.47508159e-02,  1.19954729e-02, -2.08627619e-03, -2.90985536e-02,\n",
       "         3.42271989e-04, -2.48183012e-02, -2.78203450e-02, -3.26306373e-03,\n",
       "        -1.13068568e-02, -3.82190756e-02, -8.83376822e-02, -2.67931893e-02,\n",
       "        -4.97603267e-02,  1.06248008e-02, -2.03505848e-02,  4.61896285e-02,\n",
       "         3.04142460e-02,  7.39258900e-02, -1.93729140e-02, -6.24436624e-02,\n",
       "        -4.30182517e-02, -2.44439952e-03,  2.31976081e-02,  2.40072478e-02,\n",
       "        -6.32212386e-02, -1.28707765e-02, -1.06627000e-02, -1.21628409e-02,\n",
       "         4.63577360e-02,  8.66870675e-03, -3.91136184e-02,  5.18054049e-03,\n",
       "        -3.37269567e-02,  4.08052690e-02,  4.56021838e-02, -5.35723800e-03,\n",
       "         1.47815049e-02,  6.52762968e-03, -1.91998444e-02,  1.32419588e-02,\n",
       "         1.28353182e-02,  3.14028077e-02,  2.19752900e-02, -1.87768433e-02,\n",
       "         9.01833549e-03,  1.66758746e-02,  1.36962370e-03,  4.85401601e-02,\n",
       "        -5.04996590e-02,  2.72835791e-02, -2.80786445e-03,  8.74805450e-03,\n",
       "         2.16660704e-02,  1.66531634e-02, -4.64341119e-02, -1.94114055e-02,\n",
       "         1.49265658e-02, -2.04601996e-02, -9.30299982e-02, -3.57578206e-03,\n",
       "         4.36929055e-02,  4.18227762e-02, -1.04739890e-02,  9.13388561e-03,\n",
       "        -1.26577094e-02,  9.28765221e-04,  3.03165112e-02,  9.25376918e-03,\n",
       "        -1.58128969e-03,  6.60841465e-02,  1.97659992e-02, -3.60443816e-02,\n",
       "        -3.43122310e-03, -3.59755829e-02,  1.49512002e-02, -2.88110375e-02,\n",
       "         1.71100330e-02,  4.95878048e-02,  3.53193879e-02,  4.19225693e-02,\n",
       "         4.83730398e-02,  1.96336005e-02, -1.70033122e-03,  9.81865823e-02,\n",
       "         1.77093912e-02, -3.84562416e-03, -4.52681482e-02, -4.13472485e-03,\n",
       "        -5.71960360e-02,  1.04758460e-02,  1.73035171e-02,  4.14520763e-02,\n",
       "         1.68829765e-02, -1.23575544e-02, -1.35784848e-02,  6.87891096e-02,\n",
       "         1.86708700e-02,  5.50276190e-02,  2.71758195e-02, -3.02900933e-02,\n",
       "         4.20797728e-02,  3.58545259e-02, -7.05273151e-02,  8.97804648e-03,\n",
       "         3.04065179e-02, -4.93477285e-03, -3.86132933e-02, -6.36185035e-02,\n",
       "        -1.28050530e-02,  1.45554775e-02, -3.86997499e-02, -1.90095361e-02,\n",
       "        -4.16538380e-02, -5.53315282e-02,  3.14248144e-03, -4.05708812e-02,\n",
       "        -4.65663569e-03,  1.20833972e-02,  3.92553657e-02, -1.48489513e-02,\n",
       "        -4.43880670e-02, -1.95002388e-02, -2.00037714e-02, -3.84879224e-02,\n",
       "         6.50727004e-02,  1.58443500e-03,  2.42224038e-02,  2.11767405e-02,\n",
       "        -2.80457176e-02,  5.06496541e-02, -3.17925327e-02, -3.93060297e-02,\n",
       "        -7.48629048e-02, -1.47938803e-02,  2.93556903e-03, -1.90884306e-03,\n",
       "        -4.62152585e-02,  2.79246122e-02,  5.36212437e-02,  5.08887507e-02,\n",
       "        -3.63443419e-02,  4.83042337e-02,  2.08877884e-02,  4.74292338e-02,\n",
       "         4.92656603e-03, -2.71410141e-02,  5.47686033e-02, -4.14410271e-02,\n",
       "        -5.68513758e-03, -3.04765329e-02,  3.94588104e-03, -3.12194899e-02,\n",
       "        -4.37382944e-02,  2.12004017e-02, -1.80493910e-02,  2.81700287e-02,\n",
       "         3.96552011e-02, -5.35950176e-02,  5.33269607e-02,  7.67337205e-03,\n",
       "        -2.33186651e-02, -1.42170051e-02,  5.31647503e-02, -3.49745862e-02,\n",
       "         6.54080957e-02,  4.37313430e-02, -7.25451857e-02,  4.89383824e-02,\n",
       "        -9.12457798e-03,  4.59331796e-02, -3.46429609e-02, -2.72386167e-02,\n",
       "        -3.04769948e-02, -4.05410975e-02,  5.07943444e-02,  2.39161197e-02,\n",
       "        -4.21275981e-02, -7.53407627e-02, -6.36631084e-05,  2.31820364e-02,\n",
       "         2.98201442e-02, -4.67950888e-02,  1.05024846e-02, -8.33882578e-03,\n",
       "        -2.53908839e-02, -2.78923661e-03, -5.80482446e-02, -3.58987972e-02,\n",
       "         1.04234098e-02, -3.31454054e-02, -2.29870919e-02,  1.90615077e-02,\n",
       "        -4.05621082e-02,  3.41114122e-03,  1.07715875e-02,  5.10822423e-02,\n",
       "        -3.88363712e-02, -3.84784862e-02,  4.38734442e-02, -3.46118957e-02,\n",
       "         1.73041131e-02,  1.62715707e-02,  2.14490071e-02, -2.26181746e-02,\n",
       "        -1.69366132e-02,  2.30086483e-02,  2.55133230e-02,  8.10869485e-02,\n",
       "         5.52573204e-02,  1.81327257e-02,  2.32691057e-02,  7.37191811e-02,\n",
       "        -2.53651906e-02,  1.41270263e-02,  7.17899716e-03,  4.39648479e-02,\n",
       "        -1.27545316e-02,  2.30465382e-02,  3.01264413e-02, -7.24178506e-03,\n",
       "         3.82401384e-02,  5.56619577e-02, -6.76997304e-02, -2.43170392e-02,\n",
       "        -1.17052738e-02, -1.58955567e-02,  4.49812822e-02, -5.12632392e-02,\n",
       "         2.38025878e-02,  3.47883925e-02, -3.94906700e-02, -3.04278433e-02,\n",
       "         3.11546195e-02, -2.13785656e-02,  3.09259649e-02,  1.42324967e-02,\n",
       "        -6.56462684e-02,  1.46022765e-02,  3.42594273e-03,  4.44189534e-02,\n",
       "         2.20310921e-03, -1.86533071e-02,  1.99844893e-02, -5.16026020e-02,\n",
       "        -4.81741503e-02,  1.30593171e-02,  1.76972952e-02, -1.19784456e-02,\n",
       "        -9.83291492e-03, -7.01445490e-02, -6.58488795e-02,  6.75936565e-02,\n",
       "        -2.80170068e-02,  7.45117618e-03,  2.41914298e-03,  1.14712827e-02],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea953768-894c-4429-ab8f-36f4ac33236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4702d3ed577041c99f333f9d2c4d9965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "929e836b-c8ea-48f2-bbf4-ea09b157c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result = hit['_source']\n",
    "        result['score'] = hit['_score']\n",
    "        result_docs.append(result)\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fed7b1a-a668-436f-9959-bfb2e75be29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = \"question_text_vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "687bf3a5-d44e-40df-8af5-90623a1698e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The course has already started. Can I still join it?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'section': 'General course-related questions',\n",
       " 'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'id': 'ee58a693',\n",
       " 'score': 0.82532895}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search_knn(field=field, vector=vec)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b13e8-91bd-4a15-a029-ded4baa05868",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch\n",
    "\n",
    "The search engine we used in Q4 computed the similarity between\n",
    "the query and ALL the vectors in our database. Usually this is \n",
    "not practical, as we may have a lot of data.\n",
    "\n",
    "Elasticsearch uses approximate techniques to make it faster. \n",
    "\n",
    "Let's evaluate how worse the results are when we switch from\n",
    "exact search (as in Q4) to approximate search with Elastic.\n",
    "\n",
    "What's hitrate for our dataset for Elastic?\n",
    "\n",
    "* **0.93**\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41afb18a-d8ea-4cbc-b44a-3969285c175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_vector_search(q):\n",
    "    vec = embedding_model.encode(q)\n",
    "    return elastic_search_knn(\"question_text_vector\", vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3460cbd0-be77-4cd8-8c9d-9304efa71e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89a24d9328d43cda8895e70a5c9a94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9398907103825137, 'mrr': 0.8516484517304189}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, es_vector_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
